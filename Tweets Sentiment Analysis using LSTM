{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4140,"sourceType":"datasetVersion","datasetId":2477}],"dockerImageVersionId":30763,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport nltk\nimport re\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,BatchNormalization, SimpleRNN, Embedding, Dropout , LSTM, Bidirectional\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping , ModelCheckpoint\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T15:23:41.667758Z","iopub.execute_input":"2025-01-07T15:23:41.668140Z","iopub.status.idle":"2025-01-07T15:23:41.673443Z","shell.execute_reply.started":"2025-01-07T15:23:41.668106Z","shell.execute_reply":"2025-01-07T15:23:41.672727Z"}},"outputs":[],"execution_count":159},{"cell_type":"code","source":"# Get column info\ndef columns_info(df):\n    cols=[]\n    dtype=[]\n    unique_v=[]\n    n_unique_v=[]\n    \n    for col in df.columns:\n        cols.append(col)\n        dtype.append(df[col].dtypes)\n        unique_v.append(df[col].unique())\n        n_unique_v.append(df[col].nunique())\n    \n    return pd.DataFrame({'names':cols,'dtypes':dtype,'unique':unique_v,'n_unique':n_unique_v}) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T14:52:02.931940Z","iopub.execute_input":"2025-01-07T14:52:02.932265Z","iopub.status.idle":"2025-01-07T14:52:02.941271Z","shell.execute_reply.started":"2025-01-07T14:52:02.932239Z","shell.execute_reply":"2025-01-07T14:52:02.940447Z"}},"outputs":[],"execution_count":129},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv',encoding='ISO-8859-1')","metadata":{"execution":{"iopub.status.busy":"2025-01-07T14:52:02.942499Z","iopub.execute_input":"2025-01-07T14:52:02.942717Z","iopub.status.idle":"2025-01-07T14:52:06.529216Z","shell.execute_reply.started":"2025-01-07T14:52:02.942695Z","shell.execute_reply":"2025-01-07T14:52:06.528449Z"},"trusted":true},"outputs":[],"execution_count":130},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2025-01-07T14:52:06.530616Z","iopub.execute_input":"2025-01-07T14:52:06.530882Z","iopub.status.idle":"2025-01-07T14:52:06.540665Z","shell.execute_reply.started":"2025-01-07T14:52:06.530856Z","shell.execute_reply":"2025-01-07T14:52:06.539761Z"},"trusted":true},"outputs":[{"execution_count":131,"output_type":"execute_result","data":{"text/plain":"   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n\n  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n0  is upset that he can't update his Facebook by ...                                                                   \n1  @Kenichan I dived many times for the ball. Man...                                                                   \n2    my whole body feels itchy and like its on fire                                                                    \n3  @nationwideclass no, it's not behaving at all....                                                                   \n4                      @Kwesidei not the whole crew                                                                    ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1467810369</th>\n      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n      <th>NO_QUERY</th>\n      <th>_TheSpecialOne_</th>\n      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811372</td>\n      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>joy_wolf</td>\n      <td>@Kwesidei not the whole crew</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":131},{"cell_type":"code","source":"# store the old column names\nold_columns = df.columns.tolist()\n\n# Rename the columns\ndf.columns = ['target','id','date','flag','user','text']\n\nnew_row = pd.DataFrame([old_columns], columns=df.columns)\n\n# Add the row at the beginning of the dataframe\ndf = pd.concat([new_row, df], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T14:52:06.541961Z","iopub.execute_input":"2025-01-07T14:52:06.542680Z","iopub.status.idle":"2025-01-07T14:52:06.728287Z","shell.execute_reply.started":"2025-01-07T14:52:06.542633Z","shell.execute_reply":"2025-01-07T14:52:06.727581Z"}},"outputs":[],"execution_count":132},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T14:52:06.730719Z","iopub.execute_input":"2025-01-07T14:52:06.731419Z","iopub.status.idle":"2025-01-07T14:52:06.741636Z","shell.execute_reply.started":"2025-01-07T14:52:06.731357Z","shell.execute_reply":"2025-01-07T14:52:06.740820Z"}},"outputs":[{"execution_count":133,"output_type":"execute_result","data":{"text/plain":"  target          id                          date      flag             user  \\\n0      0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n1      0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n2      0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n3      0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n4      0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n\n                                                text  \n0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n1  is upset that he can't update his Facebook by ...  \n2  @Kenichan I dived many times for the ball. Man...  \n3    my whole body feels itchy and like its on fire   \n4  @nationwideclass no, it's not behaving at all....  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>id</th>\n      <th>date</th>\n      <th>flag</th>\n      <th>user</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":133},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T14:52:06.742912Z","iopub.execute_input":"2025-01-07T14:52:06.743526Z","iopub.status.idle":"2025-01-07T14:52:06.750444Z","shell.execute_reply.started":"2025-01-07T14:52:06.743498Z","shell.execute_reply":"2025-01-07T14:52:06.749607Z"}},"outputs":[{"execution_count":134,"output_type":"execute_result","data":{"text/plain":"(1600000, 6)"},"metadata":{}}],"execution_count":134},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2025-01-07T14:52:06.751674Z","iopub.execute_input":"2025-01-07T14:52:06.751962Z","iopub.status.idle":"2025-01-07T14:52:06.758380Z","shell.execute_reply.started":"2025-01-07T14:52:06.751921Z","shell.execute_reply":"2025-01-07T14:52:06.757516Z"},"trusted":true},"outputs":[{"execution_count":135,"output_type":"execute_result","data":{"text/plain":"Index(['target', 'id', 'date', 'flag', 'user', 'text'], dtype='object')"},"metadata":{}}],"execution_count":135},{"cell_type":"code","source":"columns_info(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T14:52:06.759460Z","iopub.execute_input":"2025-01-07T14:52:06.759747Z","iopub.status.idle":"2025-01-07T14:52:09.889298Z","shell.execute_reply.started":"2025-01-07T14:52:06.759709Z","shell.execute_reply":"2025-01-07T14:52:09.888430Z"}},"outputs":[{"execution_count":136,"output_type":"execute_result","data":{"text/plain":"    names  dtypes                                             unique  n_unique\n0  target  object                                          [0, 0, 4]         3\n1      id  object  [1467810369, 1467810672, 1467810917, 146781118...   1598315\n2    date  object  [Mon Apr 06 22:19:45 PDT 2009, Mon Apr 06 22:1...    774363\n3    flag  object                                         [NO_QUERY]         1\n4    user  object  [_TheSpecialOne_, scotthamilton, mattycus, Ell...    659775\n5    text  object  [@switchfoot http://twitpic.com/2y1zl - Awww, ...   1581466","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>names</th>\n      <th>dtypes</th>\n      <th>unique</th>\n      <th>n_unique</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>target</td>\n      <td>object</td>\n      <td>[0, 0, 4]</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id</td>\n      <td>object</td>\n      <td>[1467810369, 1467810672, 1467810917, 146781118...</td>\n      <td>1598315</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>date</td>\n      <td>object</td>\n      <td>[Mon Apr 06 22:19:45 PDT 2009, Mon Apr 06 22:1...</td>\n      <td>774363</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>flag</td>\n      <td>object</td>\n      <td>[NO_QUERY]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>user</td>\n      <td>object</td>\n      <td>[_TheSpecialOne_, scotthamilton, mattycus, Ell...</td>\n      <td>659775</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>text</td>\n      <td>object</td>\n      <td>[@switchfoot http://twitpic.com/2y1zl - Awww, ...</td>\n      <td>1581466</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":136},{"cell_type":"code","source":"df['tweets'] = df['text']\ndf['target'] = df['target'].map({0: 0, 4: 1})  # Map target values to binary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T14:52:09.890625Z","iopub.execute_input":"2025-01-07T14:52:09.891000Z","iopub.status.idle":"2025-01-07T14:52:09.960863Z","shell.execute_reply.started":"2025-01-07T14:52:09.890962Z","shell.execute_reply":"2025-01-07T14:52:09.960178Z"}},"outputs":[],"execution_count":137},{"cell_type":"code","source":"df.fillna(df['target'].median())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T14:52:09.961959Z","iopub.execute_input":"2025-01-07T14:52:09.962551Z","iopub.status.idle":"2025-01-07T14:52:10.806109Z","shell.execute_reply.started":"2025-01-07T14:52:09.962512Z","shell.execute_reply":"2025-01-07T14:52:10.805214Z"}},"outputs":[{"execution_count":138,"output_type":"execute_result","data":{"text/plain":"         target          id                          date      flag  \\\n0           1.0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n1           0.0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n2           0.0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n3           0.0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n4           0.0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n...         ...         ...                           ...       ...   \n1599995     1.0  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n1599996     1.0  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n1599997     1.0  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n1599998     1.0  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n1599999     1.0  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n\n                    user                                               text  \\\n0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n1          scotthamilton  is upset that he can't update his Facebook by ...   \n2               mattycus  @Kenichan I dived many times for the ball. Man...   \n3                ElleCTF    my whole body feels itchy and like its on fire    \n4                 Karoli  @nationwideclass no, it's not behaving at all....   \n...                  ...                                                ...   \n1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...   \n1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...   \n1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...   \n1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...   \n1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...   \n\n                                                    tweets  \n0        @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n1        is upset that he can't update his Facebook by ...  \n2        @Kenichan I dived many times for the ball. Man...  \n3          my whole body feels itchy and like its on fire   \n4        @nationwideclass no, it's not behaving at all....  \n...                                                    ...  \n1599995  Just woke up. Having no school is the best fee...  \n1599996  TheWDB.com - Very cool to hear old Walt interv...  \n1599997  Are you ready for your MoJo Makeover? Ask me f...  \n1599998  Happy 38th Birthday to my boo of alll time!!! ...  \n1599999  happy #charitytuesday @theNSPCC @SparksCharity...  \n\n[1600000 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>id</th>\n      <th>date</th>\n      <th>flag</th>\n      <th>user</th>\n      <th>text</th>\n      <th>tweets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1599995</th>\n      <td>1.0</td>\n      <td>2193601966</td>\n      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>AmandaMarie1028</td>\n      <td>Just woke up. Having no school is the best fee...</td>\n      <td>Just woke up. Having no school is the best fee...</td>\n    </tr>\n    <tr>\n      <th>1599996</th>\n      <td>1.0</td>\n      <td>2193601969</td>\n      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>TheWDBoards</td>\n      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n    </tr>\n    <tr>\n      <th>1599997</th>\n      <td>1.0</td>\n      <td>2193601991</td>\n      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>bpbabe</td>\n      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n    </tr>\n    <tr>\n      <th>1599998</th>\n      <td>1.0</td>\n      <td>2193602064</td>\n      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>tinydiamondz</td>\n      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n    </tr>\n    <tr>\n      <th>1599999</th>\n      <td>1.0</td>\n      <td>2193602129</td>\n      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>RyanTrevMorris</td>\n      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1600000 rows × 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":138},{"cell_type":"code","source":"import nltk\nimport re\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords","metadata":{"execution":{"iopub.status.busy":"2025-01-07T14:52:10.808605Z","iopub.execute_input":"2025-01-07T14:52:10.808861Z","iopub.status.idle":"2025-01-07T14:52:10.812861Z","shell.execute_reply.started":"2025-01-07T14:52:10.808836Z","shell.execute_reply":"2025-01-07T14:52:10.811950Z"},"trusted":true},"outputs":[],"execution_count":139},{"cell_type":"code","source":"nltk.download('stopwords')\nstop_words = set(stopwords.words('english'))\nps = PorterStemmer()\n","metadata":{"execution":{"iopub.status.busy":"2025-01-07T14:52:10.813857Z","iopub.execute_input":"2025-01-07T14:52:10.814105Z","iopub.status.idle":"2025-01-07T14:52:10.822554Z","shell.execute_reply.started":"2025-01-07T14:52:10.814080Z","shell.execute_reply":"2025-01-07T14:52:10.821736Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}],"execution_count":140},{"cell_type":"code","source":"# def clean_text(tweet):\n#     tweet=re.sub('(#|@)\\w*',\"\",tweet)# \\w [a-z|A_Z|0-9|_]\n#     tweet=re.sub(\"https?:\\/\\/\\S+\",\"\",tweet)\n#     tweet=re.sub(\"(\\?|!)+\",\" \",tweet)\n#     tweet=re.sub(\"\\s\\d+\\s\",\"\",tweet)\n#     tweet=re.sub(\"(\\.|\\,)+\",\"\",tweet)\n#     tweet=re.sub(\"^\\s+\",\"\",tweet)\n#     tweet=re.sub(\"\\s+$\",\"\",tweet)\n#     tweet=re.sub(\"^[RT]\",\"\",tweet)\n#     # tweet=re.sub(\":+\",\"\",tweet)\n#     # tweet=re.sub(\"\\\"\\\"\",\"\",tweet)\n#     # tweet=re.sub(\"-\",\"\",tweet)\n#     # tweet=re.sub(\"w/\",\"\",tweet)\n\n\n#     return tweet\n\ndef clean_text(tweet):\n    tweet = re.sub(r\"(#|@)\\w*\", \"\", tweet)\n    tweet = re.sub(r\"https?:\\/\\/\\S+\", \"\", tweet)\n    tweet = re.sub(r\"[^\\w\\s]\", \"\", tweet)\n    tweet = tweet.lower()\n    words = tweet.split()\n    words = [ps.stem(word) for word in words if word not in stop_words]\n    return \" \".join(words)","metadata":{"execution":{"iopub.status.busy":"2025-01-07T14:52:10.823583Z","iopub.execute_input":"2025-01-07T14:52:10.823893Z","iopub.status.idle":"2025-01-07T14:52:10.829508Z","shell.execute_reply.started":"2025-01-07T14:52:10.823860Z","shell.execute_reply":"2025-01-07T14:52:10.828756Z"},"trusted":true},"outputs":[],"execution_count":141},{"cell_type":"code","source":"# def process_sentence(tweets): # tweets: all tweets\n#   clean_tweets = []\n#   for tweet in tweets:\n#     tweet = clean_text(tweet)\n#     tweet = tweet.split() # List of words\n#     c_tweet = [word.lower() for word in tweet if word.lower() not in stop_words] # Remove all stop words, and convert all words to lower case.\n\n#     ps = PorterStemmer()\n#     clean_t = [ps.stem(word) for word in c_tweet]\n#     clean_t = \" \".join(clean_t)\n#     clean_tweets.append(clean_t)\n#   return clean_tweets\n\ndef process_sentence(tweets, stop_words):\n    \"\"\"\n    Processes a list of tweets by cleaning, tokenizing, removing stopwords, and stemming.\n\n    Parameters:\n    - tweets (list): List of raw tweet strings.\n    - stop_words (set): Set of stopwords to exclude from the tweets.\n\n    Returns:\n    - clean_tweets (list): List of processed tweets as strings.\n    \"\"\"\n    ps = PorterStemmer()  # Initialize the stemmer once\n    clean_tweets = []\n\n    for tweet in tweets:\n        if not isinstance(tweet, str):  # Skip non-string values\n            clean_tweets.append(\"\")  # Add an empty string for invalid entries\n            continue\n\n        # Clean text\n        tweet = clean_text(tweet)\n\n        # Tokenize and process words\n        words = tweet.split()\n        processed_words = [ps.stem(word) for word in words if word not in stop_words]\n\n        # Recombine processed words into a single string\n        clean_tweets.append(\" \".join(processed_words))\n\n    return clean_tweets\n","metadata":{"execution":{"iopub.status.busy":"2025-01-07T14:52:10.830533Z","iopub.execute_input":"2025-01-07T14:52:10.830791Z","iopub.status.idle":"2025-01-07T14:52:10.842015Z","shell.execute_reply.started":"2025-01-07T14:52:10.830766Z","shell.execute_reply":"2025-01-07T14:52:10.841190Z"},"trusted":true},"outputs":[],"execution_count":142},{"cell_type":"code","source":"# Preprocess tweets\ndf['tweets'] = process_sentence(df['tweets'].tolist(), stop_words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T14:52:10.843133Z","iopub.execute_input":"2025-01-07T14:52:10.843730Z","iopub.status.idle":"2025-01-07T14:58:26.765096Z","shell.execute_reply.started":"2025-01-07T14:52:10.843689Z","shell.execute_reply":"2025-01-07T14:58:26.764272Z"}},"outputs":[],"execution_count":143},{"cell_type":"code","source":"# max_feature=2500\n# tokenizer=Tokenizer(num_words=max_feature,split=' ',lower=True ,oov_token='UNK')\n# tokenizer.fit_on_texts(df1['tweets'].values)\n\n# x = tokenizer.texts_to_sequences(df1['tweets'].values)\n# print(x[5])\n# x=pad_sequences(x)\n# # pad_sequences ensures that all sequences are of the same length by adding padding (usually zeros) to shorter sequences or truncating longer ones.\n# print(x[0])\n\n\n# Tokenization and padding\nmax_features = 2500\ntokenizer = Tokenizer(num_words=max_features, oov_token='UNK')\ntokenizer.fit_on_texts(df['text'].values)\nx = tokenizer.texts_to_sequences(df['text'].values)\nx = pad_sequences(x)","metadata":{"execution":{"iopub.status.busy":"2025-01-07T14:58:26.766171Z","iopub.execute_input":"2025-01-07T14:58:26.766489Z","iopub.status.idle":"2025-01-07T14:59:17.634235Z","shell.execute_reply.started":"2025-01-07T14:58:26.766460Z","shell.execute_reply":"2025-01-07T14:59:17.633519Z"},"trusted":true},"outputs":[],"execution_count":144},{"cell_type":"code","source":"y = np.array(df['target'])","metadata":{"execution":{"iopub.status.busy":"2025-01-07T14:59:17.635136Z","iopub.execute_input":"2025-01-07T14:59:17.635375Z","iopub.status.idle":"2025-01-07T14:59:17.641557Z","shell.execute_reply.started":"2025-01-07T14:59:17.635351Z","shell.execute_reply":"2025-01-07T14:59:17.640745Z"},"trusted":true},"outputs":[],"execution_count":145},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2025-01-07T14:59:17.642516Z","iopub.execute_input":"2025-01-07T14:59:17.642760Z","iopub.status.idle":"2025-01-07T14:59:18.016730Z","shell.execute_reply.started":"2025-01-07T14:59:17.642736Z","shell.execute_reply":"2025-01-07T14:59:18.015803Z"},"trusted":true},"outputs":[],"execution_count":146},{"cell_type":"code","source":"print(\"x_train\", x_train.shape)\nprint(\"y_train\", y_train.shape)\nprint(\"x_test\", x_test.shape)\nprint(\"y_test\", y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2025-01-07T14:59:18.017708Z","iopub.execute_input":"2025-01-07T14:59:18.017964Z","iopub.status.idle":"2025-01-07T14:59:18.023139Z","shell.execute_reply.started":"2025-01-07T14:59:18.017938Z","shell.execute_reply":"2025-01-07T14:59:18.022236Z"},"trusted":true},"outputs":[{"name":"stdout","text":"x_train (1280000, 118)\ny_train (1280000,)\nx_test (320000, 118)\ny_test (320000,)\n","output_type":"stream"}],"execution_count":147},{"cell_type":"code","source":"print(np.any(np.isnan(x_train)), np.any(np.isnan(y_train)))  # Identify the problematic array\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T15:09:16.949315Z","iopub.execute_input":"2025-01-07T15:09:16.949952Z","iopub.status.idle":"2025-01-07T15:09:17.001998Z","shell.execute_reply.started":"2025-01-07T15:09:16.949916Z","shell.execute_reply":"2025-01-07T15:09:17.000964Z"}},"outputs":[{"name":"stdout","text":"False True\n","output_type":"stream"}],"execution_count":152},{"cell_type":"code","source":"nan_rows = np.where(np.isnan(x_train))\nprint(\"NaN in x_train at rows:\", nan_rows)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T15:09:07.490345Z","iopub.execute_input":"2025-01-07T15:09:07.491233Z","iopub.status.idle":"2025-01-07T15:09:07.858158Z","shell.execute_reply.started":"2025-01-07T15:09:07.491196Z","shell.execute_reply":"2025-01-07T15:09:07.857293Z"}},"outputs":[{"name":"stdout","text":"NaN in x_train at rows: (array([], dtype=int64), array([], dtype=int64))\n","output_type":"stream"}],"execution_count":151},{"cell_type":"code","source":"nan_rows = np.where(np.isnan(y_train))\nprint(\"NaN in y_train at rows:\", nan_rows)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T15:09:30.654549Z","iopub.execute_input":"2025-01-07T15:09:30.654894Z","iopub.status.idle":"2025-01-07T15:09:30.660593Z","shell.execute_reply.started":"2025-01-07T15:09:30.654865Z","shell.execute_reply":"2025-01-07T15:09:30.659605Z"}},"outputs":[{"name":"stdout","text":"NaN in y_train at rows: (array([812656]),)\n","output_type":"stream"}],"execution_count":153},{"cell_type":"code","source":"x_train = np.nan_to_num(x_train, nan=0.0)  # Replace NaN with 0\ny_train = np.nan_to_num(y_train, nan=0.0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T15:09:55.831420Z","iopub.execute_input":"2025-01-07T15:09:55.832242Z","iopub.status.idle":"2025-01-07T15:09:56.071300Z","shell.execute_reply.started":"2025-01-07T15:09:55.832192Z","shell.execute_reply":"2025-01-07T15:09:56.070241Z"}},"outputs":[],"execution_count":154},{"cell_type":"code","source":"# Ensure no NaN or empty sequences\nx_train = pad_sequences(x_train, padding='post')\nx_test = pad_sequences(x_test, padding='post')\nassert not np.any(np.isnan(x_train)) and not np.any(np.isnan(y_train)), \"NaN values found!\"\n\n# Normalize input data if necessary\nx_train = x_train / np.max(x_train)\nx_test = x_test / np.max(x_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T15:09:57.836367Z","iopub.execute_input":"2025-01-07T15:09:57.837036Z","iopub.status.idle":"2025-01-07T15:10:00.924217Z","shell.execute_reply.started":"2025-01-07T15:09:57.836999Z","shell.execute_reply":"2025-01-07T15:10:00.923429Z"}},"outputs":[],"execution_count":155},{"cell_type":"code","source":"# embedding_dimension=250\n# lstm_units=196\n# model=Sequential()\n# model.add(Embedding(max_feature,embedding_dimension,input_length=x.shape[1]))\n# model.add(Dropout(0.2))\n# model.add(LSTM(lstm_units))\n# model.add(Dropout(0.2))\n# # model.add(SimpleRNN(units=lstm_units))\n# model.add(Dense(1,activation='sigmoid'))\n# model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n# # y=pd.get_dummies(df['target']).values\n\nmodel = Sequential([\n    Embedding(max_features, embedding_dim),\n    Dropout(0.2),\n    Bidirectional(LSTM(lstm_units, return_sequences=True)),\n    Dropout(0.2),\n    Bidirectional(LSTM(lstm_units//2)),\n    Dropout(0.2),\n    Dense(64, activation='relu'),\n    BatchNormalization(),\n    Dense(1, activation='sigmoid')\n])\n\n# Increase embedding dimension\nembedding_dim = 300\nlstm_units = 256\n\n# Adjust optimizer\nopt = Adam(learning_rate=0.001, clipvalue=1.0)\nmodel.compile(\n    optimizer=opt,\n    loss='binary_crossentropy',\n    metrics=['accuracy', 'AUC']\n)","metadata":{"execution":{"iopub.status.busy":"2025-01-07T15:23:45.652129Z","iopub.execute_input":"2025-01-07T15:23:45.652501Z","iopub.status.idle":"2025-01-07T15:23:45.692546Z","shell.execute_reply.started":"2025-01-07T15:23:45.652467Z","shell.execute_reply":"2025-01-07T15:23:45.691833Z"},"trusted":true},"outputs":[],"execution_count":160},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\ncallbacks = [\n    EarlyStopping(\n        monitor='val_loss',\n        patience=3,\n        restore_best_weights=True\n    ),\n    ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.5,\n        patience=2,\n        min_lr=1e-6\n    )\n]\n\nmodel = model.fit(\n    x_train, y_train,\n    epochs=20,\n    batch_size=32,\n    validation_data=(x_test, y_test),\n    callbacks=callbacks\n)","metadata":{"execution":{"iopub.status.busy":"2025-01-07T15:30:18.405355Z","iopub.execute_input":"2025-01-07T15:30:18.405740Z","iopub.status.idle":"2025-01-07T15:30:21.585939Z","shell.execute_reply.started":"2025-01-07T15:30:18.405707Z","shell.execute_reply":"2025-01-07T15:30:21.584682Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x7f929f670e50>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/weakref.py\", line 370, in remove\n    def remove(k, selfref=ref(self)):\nKeyboardInterrupt: \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[164], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping, ReduceLROnPlateau\n\u001b[1;32m      3\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m     EarlyStopping(\n\u001b[1;32m      5\u001b[0m         monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     15\u001b[0m ]\n\u001b[0;32m---> 17\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:278\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    271\u001b[0m     (\n\u001b[1;32m    272\u001b[0m         val_x,\n\u001b[1;32m    273\u001b[0m         val_y,\n\u001b[1;32m    274\u001b[0m         val_sample_weight,\n\u001b[1;32m    275\u001b[0m     ) \u001b[38;5;241m=\u001b[39m data_adapter_utils\u001b[38;5;241m.\u001b[39munpack_x_y_sample_weight(validation_data)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# Create an iterator that yields batches for one epoch.\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m epoch_iterator \u001b[38;5;241m=\u001b[39m \u001b[43mTFEpochIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# Container that configures and calls callbacks.\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:625\u001b[0m, in \u001b[0;36mTFEpochIterator.__init__\u001b[0;34m(self, distribute_strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribute_strategy \u001b[38;5;241m=\u001b[39m distribute_strategy\n\u001b[0;32m--> 625\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedDataset):\n\u001b[1;32m    627\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribute_strategy\u001b[38;5;241m.\u001b[39mexperimental_distribute_dataset(\n\u001b[1;32m    628\u001b[0m         dataset\n\u001b[1;32m    629\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:634\u001b[0m, in \u001b[0;36mTFEpochIterator._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_iterator\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tf_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/array_data_adapter.py:236\u001b[0m, in \u001b[0;36mArrayDataAdapter.get_tf_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    234\u001b[0m     indices_dataset \u001b[38;5;241m=\u001b[39m indices_dataset\u001b[38;5;241m.\u001b[39mmap(tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle)\n\u001b[0;32m--> 236\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mslice_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m options \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mOptions()\n\u001b[1;32m    239\u001b[0m options\u001b[38;5;241m.\u001b[39mexperimental_distribute\u001b[38;5;241m.\u001b[39mauto_shard_policy \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    240\u001b[0m     tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mAutoShardPolicy\u001b[38;5;241m.\u001b[39mDATA\n\u001b[1;32m    241\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/array_data_adapter.py:197\u001b[0m, in \u001b[0;36mArrayDataAdapter.get_tf_dataset.<locals>.slice_inputs\u001b[0;34m(indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    191\u001b[0m inputs \u001b[38;5;241m=\u001b[39m array_slicing\u001b[38;5;241m.\u001b[39mconvert_to_sliceable(\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inputs, target_backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m )\n\u001b[1;32m    194\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mlists_to_tuples(inputs)\n\u001b[1;32m    196\u001b[0m dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mzip(\n\u001b[0;32m--> 197\u001b[0m     (indices_dataset, \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrepeat())\n\u001b[1;32m    198\u001b[0m )\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrab_batch\u001b[39m(i, data):\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrab_one\u001b[39m(x):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:741\u001b[0m, in \u001b[0;36mDatasetV2.from_tensors\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# from_tensors_op -> dataset_ops).\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_tensors_op\n\u001b[0;32m--> 741\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_tensors_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_tensors_op.py:23\u001b[0m, in \u001b[0;36m_from_tensors\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_tensors\u001b[39m(tensors, name):  \u001b[38;5;66;03m# pylint: disable=unused-private-name\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_TensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_tensors_op.py:35\u001b[0m, in \u001b[0;36m_TensorDataset.__init__\u001b[0;34m(self, element, name)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_structure, element)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m---> 35\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_flat_tensor_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_structure\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_metadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(variant_tensor)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:7686\u001b[0m, in \u001b[0;36mtensor_dataset\u001b[0;34m(components, output_shapes, metadata, name)\u001b[0m\n\u001b[1;32m   7684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   7685\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 7686\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   7687\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTensorDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7688\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   7690\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":164},{"cell_type":"code","source":"# Visulalizing the model accuracy on the training data and test data\n\nplt.plot(history.history['accuracy']) # plotting the training accuracy from history key in the history variable\nplt.plot(history.history['val_accuracy']) # plotting the test accuracy from history key in the history variable\nplt.title('model accuracy')  # title of the plot\nplt.ylabel('accuracy') # name of y-axis\nplt.xlabel('epoch') # name of x-axis\nplt.legend(['train', 'test'], loc='upper left') # legend and it's location","metadata":{"execution":{"iopub.status.busy":"2025-01-07T15:07:54.683099Z","iopub.status.idle":"2025-01-07T15:07:54.683376Z","shell.execute_reply.started":"2025-01-07T15:07:54.683238Z","shell.execute_reply":"2025-01-07T15:07:54.683253Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visulalizing the model loss on the training data and test data\nplt.plot(history.history['loss']) # plotting the training loss from history key in the history variable\nplt.plot(history.history['val_loss']) # plotting the test loss from history key in the history variable\nplt.title('model loss') # title of the plot\nplt.ylabel('loss') # name of y-axis\nplt.xlabel('epoch')  # name of x-axis\nplt.legend(['train','test'],loc='upper left') # legend and it's location","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T15:07:54.684475Z","iopub.status.idle":"2025-01-07T15:07:54.684794Z","shell.execute_reply.started":"2025-01-07T15:07:54.684646Z","shell.execute_reply":"2025-01-07T15:07:54.684662Z"}},"outputs":[],"execution_count":null}]}